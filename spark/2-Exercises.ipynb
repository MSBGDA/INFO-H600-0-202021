{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "## 1. Sensor data exercises\n",
    "In the file “data/sensors/sensor-sample.txt” you will find on each line, multiple fields of information, let’s call them : Date(Date), Time(Time), RoomId(Integer)-SensorId(Integer), Value1(float), Value2(float)\n",
    "Using this file, use spark to compute the following queries :\n",
    "\n",
    "1. Count the number of entries for each day.\n",
    "2. Count the number of measures for each pair of RoomId-SensorId.\n",
    "3. Compute the average of Value1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Movielens movie data exercises\n",
    "\n",
    "Movielens (https://movielens.org/) is a website that provides non-commercial, personalised movie recommendations. GroupLens Research has collected and made available rating data sets from the MovieLens web site for the purpose of research into making recommendation services. In this exercise, we will use one of these datasets (the movielens latest dataset, http://files.grouplens.org/datasets/movielens/ml-latest-small.zip) and compute some basic queries on it.\n",
    "The dataset has already been downloaded and is available at data/movielens/movies.csv, data/movielens/ratings.csv, data/movielens/tags.csv, data/movielens/links.csv\n",
    "\n",
    "1. Inspect the dataset's [README file](http://files.grouplens.org/datasets/movielens/ml-latest-small-README.html), in particular the section titled \"Content and Use of Files\" to learn the structure of these three files.\n",
    "2. Compute all pairs (`movieid`, `rat`) where `movieid` is a movie id (as found in ratings.csv) and `rat` is the average rating of that movie id. (Hint: use aggregateByKey to compute first the sum of all ratings as well as the number of ratings per key).\n",
    "2. Compute all pairs (`title`, `rat`) where `title` is a full movie title (as found in the movies.csv file), and `rat` is the average rating of that movie (computed over all possible ratings for that movie, as found in the ratings.csv file)\n",
    "3. [_Extra_] Compute all pairs (`title`, `tag`) where `title` is a full movie title that has an average rating of at least 3.5, and `tag` is a tag for that movie (as found in the tags.csv file)\n",
    "\n",
    "Extra: if you want to experiment with larger datasets, download the 10m dataset (http://files.grouplens.org/datasets/movielens/ml-10m.zip, 250 Mb uncompressed) and re-do the exercises above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Github log data exercises\n",
    "Github makes activity logs publicly available at https://www.githubarchive.org/. One such log file, which contains activity data for 2015-03-01 between 0h-1h at night, has been downloaded and is available at `data/github/2015-03-01-0.json.gz`. This (compressed) file contains multiple JSON objects, one per line. Here is a sample line of this file, neatly formatted:\n",
    "\n",
    "`{ \"id\": \"2614896652\",\n",
    "    \"type\": \"CreateEvent\",\n",
    "    \"actor\": {\n",
    "        \"id\": 739622,\n",
    "        \"login\": \"treydock\",\n",
    "        \"gravatar_id\": \"\",\n",
    "        \"url\": \"https://api.githb.com/users/treydock\",\n",
    "        \"avatar_url\": \"https://avatars.githubusercontent.com/u/739622?\"\n",
    "    },\n",
    "    \"repo\": {\n",
    "        \"id\": 23934080,\n",
    "        \"name\": \"Early-Modern-OCR/emop-dashboard\",\n",
    "    \"url\": \"https://api.github.com/repos/Early-Modern-OCR/emop-dashboard\"\n",
    "    },\n",
    "    \"payload\": {\n",
    "        \"ref\": \"development\",\n",
    "        \"ref_type\": \"branch\",\n",
    "        \"master-branch\": \"master\",\n",
    "        \"description\": \"\",\n",
    "        \"pusher_type\": \"user\",\n",
    "    },\n",
    "    \"public\": true,\n",
    "    \"created_at\": \"2015-03-01T00:00:00Z\",\n",
    "    \"org\": {\n",
    "        \"id\": 10965476,\n",
    "        \"login\": \"Early-Modern-OCR\",\n",
    "        \"gravatar_id\": \"\",\n",
    "        \"url\": \"https://api.github.com/orgs/Early-Modern-OCR\",\n",
    "        \"avatar_url\": \"https://avatars.githubusercontent.com/u/10965476?\"\n",
    "    }\n",
    "}`\n",
    "\n",
    "This log entry has `CreateEvent` type and its `payload.ref_type` is `branch` . So someone named \"treydock\" (`actor.login`) created a repository branch called \"development\" (`payload.ref`) in the first second of March 1, 2015 (`created_at`) .\n",
    "\n",
    "1. Load the textfile into an RDD (note: spark can read gzipped files directly!). Convert this RDD (which consists of string elements) to an RDD where each element is a JSON object (hint: use the `json.loads` function from the `json` module to convert a string into a JSON object).\n",
    "\n",
    "2. Filter this RDD of JSON objects to retain only those objects that represent push activities (where `type` equals `PushEvent`)\n",
    "\n",
    "3. Count the number of push events.\n",
    "\n",
    "4. Compute the number of push events, grouped per `actor.login`. \n",
    "\n",
    "5. Retrieve the results of (4) in sorted order, where logins with higher number of pushes come first. Retrieve the 10 first such results (which contain the highest number of pushes)\n",
    "\n",
    "6. You are representing a company and need to retrieving the number of pushes for every employee in the company. The file `data/github/employees.txt` contains a list of all employee login names at your company.\n",
    "\n",
    "Extra: if you want to experiment with larger datasets, download more log data from the github archive website and re-do the exercises above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
