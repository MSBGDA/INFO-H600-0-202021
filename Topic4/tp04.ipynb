{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO-H-600-Computing foundations of data scienes\n",
    "## TP 4 - Sets, dictionnaries and files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author: Kubam Ivo\n",
    "### Date: 10/18/2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ex. 1. Write a function word_in_file(word, fname) that detects if a word given as argument is in a file which name is also provided as argument (fname). We suppose that the file contains one word per line. There is no supposition on the order of the words in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def word_in_file(word,fname):\n",
    "    f = open(fname)\n",
    "    for l in f.readlines():\n",
    "        if word in l:\n",
    "            f.close()\n",
    "            return True\n",
    "    f.close()\n",
    "    return False\n",
    "        \n",
    "word_in_file(\"croisiere\", \"test.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ex. 2. Write a function longest_word(fname) that finds the longest word in a file (the name fname of the file is given as argument). The result must be returned as a tuple containing the longest word and its length. As for the previous exercices, we suppose that each line containes only on word per line with no information about the order of the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zero', 'un', 'deux', 'trois', 'quatre', 'cinq']\n",
      "[4, 2, 4, 5, 6, 4]\n",
      "(6, 'quatre')\n"
     ]
    }
   ],
   "source": [
    "def longest_word(fname):\n",
    "    f = open(fname)\n",
    "    max_len = 0\n",
    "    word = []\n",
    "    length = []\n",
    "    for l in f.readlines():\n",
    "        word.append(l.replace(\"\\n\",\"\"))\n",
    "        length.append(len(l.replace(\"\\n\",\"\")))\n",
    "    for i in range(len(length)):\n",
    "        if length[i] > max_len:\n",
    "            x = length[i]\n",
    "            y = word[i]\n",
    "            max_len = length[i]\n",
    "    result = (x,y)\n",
    "    print(word);print(length)\n",
    "    print(result)\n",
    "\n",
    "longest_word(\"test2.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ex. 3. Write a function that return a dictionnary composed of the number of occurencts of each word of 2 letters (AA, AC, AG, . . . ) contained in a sequence of nucleotide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AA': 1, 'AC': 1, 'AG': 7, 'AT': 2, 'CA': 1, 'CC': 3, 'CG': 1, 'CT': 8, 'GA': 1, 'GC': 7, 'GG': 1, 'GT': 1, 'TA': 7, 'TC': 2, 'TG': 2, 'TT': 1}\n"
     ]
    }
   ],
   "source": [
    "def sort(ls):\n",
    "    ls_sort = []\n",
    "    \n",
    "    for elt in ls:\n",
    "        pos = len(ls)-1\n",
    "        for i in range(len(ls)):\n",
    "            if elt < ls[i]:\n",
    "                pos -= 1\n",
    "        ls_sort.insert(pos, elt)\n",
    "    return ls_sort    \n",
    "        \n",
    "def occurence_2_letters(word):\n",
    "    word1 = set(word)\n",
    "    unique_let = word1\n",
    "    unique_list = []\n",
    "    for let in unique_let:\n",
    "        unique_list.append(let)\n",
    "    unique_sort = sort(unique_list)\n",
    "    pair_let = []\n",
    "    pair_dict = {}\n",
    "    for let1 in unique_sort:\n",
    "        for let2 in unique_sort:\n",
    "            pair_let.append(let1+let2)\n",
    "    for pair in pair_let:\n",
    "        pair_count = word.count(pair)\n",
    "        pair = pair\n",
    "        pair_dict[pair] = pair_count\n",
    "    return pair_dict\n",
    "        \n",
    "   \n",
    "\n",
    "            \n",
    "        \n",
    "    \n",
    "print(occurence_2_letters(\"ACCTAGCCATGTAGAATCGCCTAGGCTTTAGCTAGCTCTAGCTAGCTG\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ex. 4. Write a function that prints the dictionnary in the following manner:\n",
    "#### Key : GT - Value : 1\n",
    "#### Key : CT - Value : 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AA: AA - value : 1\n",
      "AC: AC - value : 1\n",
      "AG: AG - value : 7\n",
      "AT: AT - value : 2\n",
      "CA: CA - value : 1\n",
      "CC: CC - value : 3\n",
      "CG: CG - value : 1\n",
      "CT: CT - value : 8\n",
      "GA: GA - value : 1\n",
      "GC: GC - value : 7\n",
      "GG: GG - value : 1\n",
      "GT: GT - value : 1\n",
      "TA: TA - value : 7\n",
      "TC: TC - value : 2\n",
      "TG: TG - value : 2\n",
      "TT: TT - value : 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def dict_print(dict_input):\n",
    "    new_dict = occurence_2_letters(dict_input)    \n",
    "    for key in new_dict:\n",
    "        print(key + ': '+ str(key)+  \" - value : \" + str(new_dict[key]))\n",
    "    \n",
    "        \n",
    "    \n",
    "\n",
    "dict_print(\"ACCTAGCCATGTAGAATCGCCTAGGCTTTAGCTAGCTCTAGCTAGCTG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ex. 5. Write a function that returns a datastructure composed of each word contained in the file dico.txt available on the UV. (If you choose to use a dictionnary, the value associated to the keys in this dictionnary has no importance in this exercise). The file dico.txt is composed of lines containing on word in capital case. Each word is present only once in the file. Then, write a function that checks if a word given in parameter is in this dictionnary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "def load_file(filename):\n",
    "    f = open(filename)\n",
    "    words = []\n",
    "    for l in f.readlines():\n",
    "        l = l.strip()\n",
    "    f.close()\n",
    "    return words\n",
    "\n",
    "def is_in_dico(word,filename):\n",
    "    words = load_file(filename)\n",
    "    for elem in words:\n",
    "        if word.upper() == elem.upper():\n",
    "            return True\n",
    "    else:\n",
    "        return False\n",
    "        \n",
    "print(is_in_dico(\"azxy\",\"dico.txt\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ex. 6. Write a function that returns a dictionnary containing the number of occurrences of each word in the file hamlet.txt which can be found on the UV. \n",
    "#### Before doing this, you should clean the text which means removing the punctuation symbols and setting all the words in upper case. Please find in the documentation which functions can help you performing this job (modul string). Then, create a function that determines which word is the most used in this text. \n",
    "#### dico = occurrences_words(\"hamlet.txt\") \n",
    "#### print(most_used_word(dico)) # -> THE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('THE', 1090)\n"
     ]
    }
   ],
   "source": [
    "def load_file2(filename):\n",
    "    '''Loads file, delete any punctuations and populates words into a list'''\n",
    "    f = open(filename)\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    words = []\n",
    "    for l in f.readlines():\n",
    "        l = l.strip()\n",
    "        words.append(l.translate(translator))\n",
    "    f.close()\n",
    "    return words\n",
    "\n",
    "def occurrences_words(filename):\n",
    "    word_list = []\n",
    "    word_set = set()\n",
    "    word_phrase = []\n",
    "    word_dict = {}\n",
    "    sentences = load_file2(\"hamlet.txt\")\n",
    "    for phrase in sentences:\n",
    "        if len(phrase)>0:\n",
    "            word_list.append(phrase.split())\n",
    "    for elem in word_list:\n",
    "        for word in elem:\n",
    "            word_set.add(word.upper())\n",
    "    unique_word = sort(list(word_set))\n",
    "    \n",
    "    \n",
    "    for elt in unique_word:\n",
    "        x = 0\n",
    "        for elem in word_list:\n",
    "            for word in elem:\n",
    "                if word.upper() == elt:\n",
    "                    x += 1\n",
    "        if len(elt)>1:\n",
    "            word_dict[elt] = x\n",
    "    return word_dict           \n",
    "        \n",
    "def most_used_word(word_dict):\n",
    "    max_length = 0\n",
    "    max_word = ''\n",
    "    \n",
    "    for cle in word_dict:\n",
    "        if word_dict[cle] > max_length:\n",
    "            max_length = word_dict[cle]\n",
    "            max_word = cle\n",
    "    return max_word, max_length\n",
    "    \n",
    "\n",
    "dico = occurrences_words(\"hamlet.txt\")   \n",
    "print(most_used_word(dico))    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file2_dict(filename):\n",
    "    address_list = load_file2(filename)\n",
    "    address_list2 = []\n",
    "    address_dict = {}\n",
    "    address_book = []\n",
    "    \n",
    "    for elem in address_list:\n",
    "        address_list2.append(elem.split())\n",
    "    for elem in address_list2:\n",
    "        if len(elem) > 0:\n",
    "            if elem[0] == 'LastName':\n",
    "                address_dict['LastName'] = elem[1]\n",
    "            elif elem[0] == 'Office':\n",
    "                address_dict['Office'] = elem[1]\n",
    "            elif elem[0] == 'FirstName':\n",
    "                address_dict['FirstName'] = elem[1]\n",
    "            elif elem[0] == 'Phone':\n",
    "                address_dict['Phone'] = elem[1]\n",
    "        else:\n",
    "            address_book.append(address_dict)\n",
    "    return address_book\n",
    "\n",
    "def show_address_book(filename):\n",
    "    address_book = load_file2_dict(filename)\n",
    "    for elem in address_book:\n",
    "        for cle in elem:\n",
    "            print(cle + \": \" + str(elem[cle]) )\n",
    "        print(20 * '=')\n",
    "\n",
    "def add_entry(LastName,  FirstName, Office = None, Phone = None , filename = 'address.txt' ):\n",
    "    address_book = load_file2_dict(filename)\n",
    "    new_entry = {}\n",
    "    new_entry['LastName'] = LastName\n",
    "    new_entry['FirstName'] = FirstName\n",
    "    if Office != None:\n",
    "        new_entry['Office'] = Office\n",
    "    elif Phone != None:\n",
    "        new_entry['Phone'] = Phone\n",
    "    address_book.append(new_entry)\n",
    "\n",
    "add_entry('Kubam', 'Ivo Mbi', )\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LastName: Jones\n",
      "Office: UB4131\n",
      "FirstName: Joe\n",
      "Phone: 026503758\n",
      "====================\n",
      "LastName: Jones\n",
      "Office: UB4131\n",
      "FirstName: Joe\n",
      "Phone: 026503758\n",
      "====================\n",
      "LastName: Jones\n",
      "Office: UB4131\n",
      "FirstName: Joe\n",
      "Phone: 026503758\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "show_address_book('address.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
